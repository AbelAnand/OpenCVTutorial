{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WntTCUDX75vxQLy-n8PsJd7W0RB0ANcy",
      "authorship_tag": "ABX9TyNHYSjHhEl2gXz7MnEtzKnO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "629489cd34ed4294acaa2f382d215291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c362a1afca2496c9ed11f0a761d52dc",
              "IPY_MODEL_715b28516c1b4329826ef7aa6e05b12d",
              "IPY_MODEL_5f992e4b3f534ea8a22a474ff148d11d"
            ],
            "layout": "IPY_MODEL_b62c2fa9135c41f0bb1f0c1799b39ddc"
          }
        },
        "6c362a1afca2496c9ed11f0a761d52dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d3ede019e5e41e1af3ed8b003db1385",
            "placeholder": "​",
            "style": "IPY_MODEL_e91e7009f4d54ff69a899e95f3567042",
            "value": "config.json: 100%"
          }
        },
        "715b28516c1b4329826ef7aa6e05b12d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0c3648422842dcaa029d0bdcf5a526",
            "max": 71813,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e857d4f7a3f4ce1973321a1afd68b1a",
            "value": 71813
          }
        },
        "5f992e4b3f534ea8a22a474ff148d11d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba077465fc3469e91b9cf406ed99cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_5b2403958a1c4a179ec0414ea006807a",
            "value": " 71.8k/71.8k [00:00&lt;00:00, 1.10MB/s]"
          }
        },
        "b62c2fa9135c41f0bb1f0c1799b39ddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d3ede019e5e41e1af3ed8b003db1385": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e91e7009f4d54ff69a899e95f3567042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff0c3648422842dcaa029d0bdcf5a526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e857d4f7a3f4ce1973321a1afd68b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ba077465fc3469e91b9cf406ed99cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2403958a1c4a179ec0414ea006807a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e5c7274092d4a2fa0d4d3cb8e21ff38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6523b09dbb244e1b434fc5eb951a689",
              "IPY_MODEL_247ab880d3aa42d7881ec830a327a9b6",
              "IPY_MODEL_11c86b448aa444f7920e5a35a00f3081"
            ],
            "layout": "IPY_MODEL_373717f6f60b43f688c9f7d4c431bc2c"
          }
        },
        "b6523b09dbb244e1b434fc5eb951a689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f111a03c5f445e9b30075e00753d657",
            "placeholder": "​",
            "style": "IPY_MODEL_ba354cece41441e6b926c46be383cf04",
            "value": "model.safetensors: 100%"
          }
        },
        "247ab880d3aa42d7881ec830a327a9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f371b37a052742d186740ffe0cccb3ce",
            "max": 113412768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_650428aeb2ab4ef0aa86a079024f173b",
            "value": 113412768
          }
        },
        "11c86b448aa444f7920e5a35a00f3081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d38814f0e3b49ad85e980c09ee99bcf",
            "placeholder": "​",
            "style": "IPY_MODEL_ea058fa3c7e1410fbde0b84ad6319645",
            "value": " 113M/113M [00:00&lt;00:00, 155MB/s]"
          }
        },
        "373717f6f60b43f688c9f7d4c431bc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f111a03c5f445e9b30075e00753d657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba354cece41441e6b926c46be383cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f371b37a052742d186740ffe0cccb3ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650428aeb2ab4ef0aa86a079024f173b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d38814f0e3b49ad85e980c09ee99bcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea058fa3c7e1410fbde0b84ad6319645": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arun-arunisto/OpenCVTutorialAbel/blob/main/UsingPretrainedSwinTransformerModelForImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SQhjhn9cbQgb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#transformation pipeline\n",
        "transform = transforms.Compose({\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "})"
      ],
      "metadata": {
        "id": "srcU6ITKbs88"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "train_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/data/brain_tumor_dataset/train', transform=transform)\n",
        "test_dataset = datasets.ImageFolder(root='/content/drive/MyDrive/data/brain_tumor_dataset/test', transform=transform)"
      ],
      "metadata": {
        "id": "xQ5K31CdcagI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "m7zqowhycwMU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using pretrained swin transformer\n",
        "from transformers import SwinForImageClassification\n",
        "\n",
        "#loading pretrained swin transformer model\n",
        "model = SwinForImageClassification.from_pretrained(\n",
        "    'microsoft/swin-tiny-patch4-window7-224',\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "629489cd34ed4294acaa2f382d215291",
            "6c362a1afca2496c9ed11f0a761d52dc",
            "715b28516c1b4329826ef7aa6e05b12d",
            "5f992e4b3f534ea8a22a474ff148d11d",
            "b62c2fa9135c41f0bb1f0c1799b39ddc",
            "4d3ede019e5e41e1af3ed8b003db1385",
            "e91e7009f4d54ff69a899e95f3567042",
            "ff0c3648422842dcaa029d0bdcf5a526",
            "4e857d4f7a3f4ce1973321a1afd68b1a",
            "5ba077465fc3469e91b9cf406ed99cb0",
            "5b2403958a1c4a179ec0414ea006807a",
            "4e5c7274092d4a2fa0d4d3cb8e21ff38",
            "b6523b09dbb244e1b434fc5eb951a689",
            "247ab880d3aa42d7881ec830a327a9b6",
            "11c86b448aa444f7920e5a35a00f3081",
            "373717f6f60b43f688c9f7d4c431bc2c",
            "1f111a03c5f445e9b30075e00753d657",
            "ba354cece41441e6b926c46be383cf04",
            "f371b37a052742d186740ffe0cccb3ce",
            "650428aeb2ab4ef0aa86a079024f173b",
            "5d38814f0e3b49ad85e980c09ee99bcf",
            "ea058fa3c7e1410fbde0b84ad6319645"
          ]
        },
        "id": "OrcNpnz5dIhN",
        "outputId": "fa74e1a2-ad6e-4b6f-892a-f805afd9f36f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/71.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "629489cd34ed4294acaa2f382d215291"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/113M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e5c7274092d4a2fa0d4d3cb8e21ff38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#freezing all layers except the final classification head\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "LFbVfaNBdmnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unfreezing the classification layer\n",
        "for param in model.classifier.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "nuqG61Rxd33f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.optim.lr_scheduler import StepLR"
      ],
      "metadata": {
        "id": "_eEJpmBUd_ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting up the optimizer and loss function\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9lHWEqP2eaMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gpu -> neural will be more faster than cpus\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgN41D4NeprZ",
        "outputId": "fb8e4d3a-42cd-4523-81a1-d9a8f5426bbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinForImageClassification(\n",
              "  (swin): SwinModel(\n",
              "    (embeddings): SwinEmbeddings(\n",
              "      (patch_embeddings): SwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): SwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
              "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-5): 6 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
              "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "#10\n",
        "for epoch in range(10):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for inputs, labels in train_loader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    #zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    #forward pass\n",
        "    outputs = model(inputs).logits\n",
        "    #calculate loss\n",
        "    loss = criterion(outputs, labels)\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    #update weights\n",
        "    optimizer.step()\n",
        "    #calculating the accuracy\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "    running_loss += loss.item()\n",
        "  #printing the training results\n",
        "  print(f\"Epoch [{epoch+1}/10], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100*correct/total:.2f}%\")\n",
        "\n",
        "  #validation\n",
        "  model.eval()\n",
        "  val_correct = 0\n",
        "  val_total = 0\n",
        "  with torch.no_grad():\n",
        "    for val_inputs, val_labels in test_loader:\n",
        "      val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
        "      val_outputs = model(val_inputs).logits\n",
        "      _, val_predicted = torch.max(val_outputs, 1)\n",
        "      val_total += val_labels.size(0)\n",
        "      val_correct += (val_predicted == val_labels).sum().item()\n",
        "  print(f\"Validation Accuracy: {100*val_correct/val_total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFzzxEgCfEu0",
        "outputId": "cb4b5a43-30c2-4c3b-c99c-63e5f583b652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6856, Accuracy: 55.89%\n",
            "Validation Accuracy: 55.41%\n",
            "Epoch [2/10], Loss: 0.6462, Accuracy: 67.68%\n",
            "Validation Accuracy: 70.27%\n",
            "Epoch [3/10], Loss: 0.6137, Accuracy: 73.18%\n",
            "Validation Accuracy: 68.24%\n",
            "Epoch [4/10], Loss: 0.5868, Accuracy: 75.53%\n",
            "Validation Accuracy: 76.35%\n",
            "Epoch [5/10], Loss: 0.5571, Accuracy: 79.35%\n",
            "Validation Accuracy: 77.03%\n",
            "Epoch [6/10], Loss: 0.5396, Accuracy: 79.46%\n",
            "Validation Accuracy: 77.70%\n",
            "Epoch [7/10], Loss: 0.5156, Accuracy: 80.25%\n",
            "Validation Accuracy: 77.70%\n",
            "Epoch [8/10], Loss: 0.5018, Accuracy: 80.70%\n",
            "Validation Accuracy: 77.70%\n",
            "Epoch [9/10], Loss: 0.4971, Accuracy: 80.58%\n",
            "Validation Accuracy: 77.70%\n",
            "Epoch [10/10], Loss: 0.4734, Accuracy: 83.28%\n",
            "Validation Accuracy: 76.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the model\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/AbelFolder/swintransformer_model.pth\")"
      ],
      "metadata": {
        "id": "z-uH93UghxLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating accuracy of the Swin Transformer Model"
      ],
      "metadata": {
        "id": "YOw2XHjbSk2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "_4pShS6vwE9u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the saved model\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/AbelFolder/swintransformer_model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGr9L34uTdH7",
        "outputId": "c398295d-d619-4d48-cfb6-94f85f3c3339"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-dfd82f1d97fb>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"/content/drive/MyDrive/AbelFolder/swintransformer_model.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0iRWaEaTkyK",
        "outputId": "674924cf-29e6-41c2-9e50-00188350055b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinForImageClassification(\n",
              "  (swin): SwinModel(\n",
              "    (embeddings): SwinEmbeddings(\n",
              "      (patch_embeddings): SwinPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "      )\n",
              "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): SwinEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (key): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (value): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=96, out_features=96, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=96, out_features=384, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=384, out_features=96, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
              "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (1): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (key): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (value): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
              "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (2): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-5): 6 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (downsample): SwinPatchMerging(\n",
              "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
              "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (3): SwinStage(\n",
              "          (blocks): ModuleList(\n",
              "            (0-1): 2 x SwinLayer(\n",
              "              (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (attention): SwinAttention(\n",
              "                (self): SwinSelfAttention(\n",
              "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "                (output): SwinSelfOutput(\n",
              "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                  (dropout): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (drop_path): SwinDropPath(p=0.1)\n",
              "              (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (intermediate): SwinIntermediate(\n",
              "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (intermediate_act_fn): GELUActivation()\n",
              "              )\n",
              "              (output): SwinOutput(\n",
              "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#opening the image\n",
        "img = Image.open(\"/content/drive/MyDrive/data/brain_tumor_dataset/train/healthy/0000.jpg\")\n",
        "img = transform(img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "J8SLZQSiTpE8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting healthy\n",
        "output = model(img).logits\n",
        "_, predicted = torch.max(output, 1)\n",
        "print(f\"Predicted class: {predicted.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBLnrNi-UCk4",
        "outputId": "a6847b02-824e-4054-fa72-a935cc0063de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting the tumor\n",
        "img = Image.open(\"/content/drive/MyDrive/data/brain_tumor_dataset/train/tumor/00004.jpg\")\n",
        "img = transform(img).unsqueeze(0).to(device)"
      ],
      "metadata": {
        "id": "swOSkYeUUggi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting healthy\n",
        "output = model(img).logits\n",
        "_, predicted = torch.max(output, 1)\n",
        "print(f\"Predicted class: {predicted.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T85zAxFU02p",
        "outputId": "2d5da8e5-4af4-460a-93a1-50901f393d3b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#healthy folder\n",
        "path = \"/content/drive/MyDrive/data/brain_tumor_dataset/test/healthy\""
      ],
      "metadata": {
        "id": "zUxJqnSCU2wL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "38HPB6pFVV1-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(path)"
      ],
      "metadata": {
        "id": "cbs5DodxVWsW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for f in files:\n",
        "  try:\n",
        "    img = Image.open(os.path.join(path, f))\n",
        "    img = transform(img).unsqueeze(0).to(device)\n",
        "    output = model(img).logits\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    print(f\"Predicted Class: {predicted.item()} | filename: {f} | Actual Class: 0\")\n",
        "  except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr7wOTx_VcST",
        "outputId": "df103bc6-f8e5-49d1-d60b-dca21517502b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 0 | filename: 0796.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0676.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0698.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0601.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0861.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0615.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0874.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0820.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0785.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0792.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0731.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0762.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0710.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0858.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0691.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0791.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0639.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0596.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0591.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0730.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0638.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0566.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0645.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0565.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0778.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0697.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0800.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0857.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0879.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0765.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0562.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0719.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0740.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0607.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0580.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0839.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0860.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0718.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0793.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0881.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0864.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0696.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0724.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0703.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0721.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0652.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0551.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0720.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0689.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0795.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0571.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0640.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0806.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0761.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0715.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0884.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0684.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0846.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0805.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0872.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0707.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0868.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0863.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0871.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0859.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0769.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0888.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0733.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0835.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0841.jpg | Actual Class: 0\n",
            "Predicted Class: 0 | filename: 0768.jpg | Actual Class: 0\n",
            "Predicted Class: 1 | filename: 0878.jpg | Actual Class: 0\n",
            "[Errno 21] Is a directory: '/content/drive/MyDrive/data/brain_tumor_dataset/test/healthy/.ipynb_checkpoints'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function for calculating accuracy\n",
        "def calculate_accuracy(model, img_path, actual_class):\n",
        "  files = os.listdir(img_path)\n",
        "  total_images = len(files)\n",
        "  predicted_ones = 0\n",
        "  for f in files:\n",
        "    try:\n",
        "      img = Image.open(os.path.join(path, f))\n",
        "      img = transform(img).unsqueeze(0).to(device)\n",
        "      output = model(img).logits\n",
        "      _, predicted = torch.max(output, 1)\n",
        "      if int(predicted.item()) == int(actual_class):\n",
        "        predicted_ones += 1\n",
        "    except Exception as e:\n",
        "      continue\n",
        "  accuracy_score = (predicted_ones/total_images)*100\n",
        "  return accuracy_score"
      ],
      "metadata": {
        "id": "5rTVgpQRVeSp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/data/brain_tumor_dataset/test/healthy\"\n",
        "actual_class = 0\n",
        "print(\"Accuracy Score:\",calculate_accuracy(model, img_path, actual_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZ0HHzXmXK_E",
        "outputId": "77f80e52-1f5a-4e4c-aaeb-073c4de97bb5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 52.054794520547944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = \"/content/drive/MyDrive/data/brain_tumor_dataset/test/tumor\"\n",
        "actual_class = 1\n",
        "print(\"Accuracy Score:\",calculate_accuracy(model, img_path, actual_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-kRmQpwXafM",
        "outputId": "e25bf72d-89e6-494d-8b15-61b8180ce9b0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score: 2.631578947368421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy Score for healthy: **52.04%**\n",
        "\n",
        "Accuracy Score for tumor: **2.63%**"
      ],
      "metadata": {
        "id": "sti2vxK9YrX3"
      }
    }
  ]
}